library(leaps)
set.seed(123) # Para reproducibilidad
n <- 100
X <- runif(n, min=0, max=10) # Variable predictora
epsilon <- rnorm(n, mean = 0, sd = 3) # Vector de ruido
beta_0 <- 5
beta_1 <- 2
beta_2 <- -3
beta_3 <- 0.3
Y <- beta_0 + beta_1 * X + beta_2 * X^2 + beta_3 * X^3 + epsilon
#scatterplot
library(ggplot2)
ggplot() +
geom_point(mapping=aes(x=X,y=Y)) +
theme_bw()
data <- data.frame(Y = Y)
for (i in 1:10) {
data[[paste0("X", i)]] <- X^i
}
library(leaps)
options(max.print=10000)
regfit.full <- regsubsets(Y ~ ., data = data, nbest=252, really.big=T, nvmax=10)
reg.summary <- summary(regfit.full)
print(reg.summary)
# Mejor subset segun bic
bics = reg.summary$bic
idx_menor = which.min(bics)
cat(paste("Numero de variables: ", sum(reg.summary$which[idx_menor,]), "\n"))
reg.summary$which[idx_menor,]
# Mejor subset segun adjr2
adjr2s = reg.summary$adjr2
idx_menor = which.min(adjr2s)
reg.summary$which[idx_menor,]
model = lm(Y ~ X1 + X5 + X7 , data=data)
ggplot() +
geom_point(mapping=aes(x=X,y=Y), color='blue') +
geom_line(mapping=aes(x=X,y=predicciones), color='red') +
theme_bw()
predicciones = predict(model, newdata=data)
ggplot() +
geom_point(mapping=aes(x=X,y=Y), color='blue') +
geom_line(mapping=aes(x=X,y=predicciones), color='red') +
theme_bw()
setwd("~/Documents/CIMAT/Tercer Semestre/Computo Estadistico/Tareas/T4")
ggsave("t4_gustavo_hernandez_plot.pdf", width=6, height=4)
ggsave("./documento/figure/p1_compare.pdf", width=6, height=4)
model
modelo_original = lm(Y ~ X1 + X2 + X3, data=data)
ggplot() +
geom_point(mapping=aes(x=X,y=Y), color='blue') +
geom_line(mapping=aes(x=X,y=predict_orig), color='green') +
geom_line(mapping=aes(x=X,y=predicciones), color='red') +
theme_bw()
modelo_original = lm(Y ~ X1 + X2 + X3, data=data)
model = lm(Y ~ X1 + X5 + X7 , data=data)
modelo_original = lm(Y ~ X1 + X2 + X3, data=data)
# Mejor subset segun bic
bics = reg.summary$bic
idx_menor = which.min(bics)
cat(paste("Numero de variables: ", sum(reg.summary$which[idx_menor,]), "\n"))
reg.summary$which[idx_menor,]
# Mejor subset segun adjr2
adjr2s = reg.summary$adjr2
idx_menor = which.min(adjr2s)
reg.summary$which[idx_menor,]
set.seed(123) # Para reproducibilidad
n <- 100
X <- runif(n, min=0, max=10) # Variable predictora
epsilon <- rnorm(n, mean = 0, sd = 3) # Vector de ruido
beta_0 <- 5
beta_1 <- 2
beta_2 <- -3
beta_3 <- 0.3
Y <- beta_0 + beta_1 * X + beta_2 * X^2 + beta_3 * X^3 + epsilon
#scatterplot
library(ggplot2)
ggplot() +
geom_point(mapping=aes(x=X,y=Y)) +
theme_bw()
data <- data.frame(Y = Y)
for (i in 1:10) {
data[[paste0("X", i)]] <- X^i
}
library(leaps)
options(max.print=10000)
regfit.full <- regsubsets(Y ~ ., data = data, nbest=252, really.big=T, nvmax=10)
reg.summary <- summary(regfit.full)
print(reg.summary)
model = lm(Y ~ X1 + X5 + X7 , data=data)
modelo_original = lm(Y ~ X1 + X2 + X3, data=data)
predicciones = predict(model, newdata=data)
predict_orig = predict(modelo_original, newdata=data)
ggplot() +
geom_point(mapping=aes(x=X,y=Y), color='blue') +
geom_line(mapping=aes(x=X,y=predict_orig), color='green') +
geom_line(mapping=aes(x=X,y=predicciones), color='red') +
theme_bw()
ggsave("./documento/figure/p1_compare.pdf", width=6, height=4)
# Mejor subset segun bic
bics = reg.summary$bic
idx_menor = which.min(bics)
cat(paste("Numero de variables: ", sum(reg.summary$which[idx_menor,]), "\n"))
reg.summary$which[idx_menor,]
# Mejor subset segun adjr2
adjr2s = reg.summary$adjr2
idx_menor = which.min(adjr2s)
reg.summary$which[idx_menor,]
model = lm(Y ~ X1 + X5 + X7 , data=data)
modelo_original = lm(Y ~ X1 + X2 + X3, data=data)
predicciones = predict(model, newdata=data)
predict_orig = predict(modelo_original, newdata=data)
ggplot() +
geom_point(mapping=aes(x=X,y=Y), color='blue') +
geom_line(mapping=aes(x=X,y=predict_orig), color='green') +
geom_line(mapping=aes(x=X,y=predicciones), color='red') +
theme_bw()
ggsave("./documento/figure/p1_compare.pdf", width=6, height=4)
?regsubsets
regfit.forward <- regsubsets(Y ~ ., data = data, method="forward")
print(reg.summary)
regfit.forward <- regsubsets(Y ~ ., data = data, method="forward")
reg.summary <- summary(regfit.forward)
print(reg.summary)
# Mejor subset segun bic
bics = reg.summary$bic
idx_menor = which.min(bics)
cat(paste("Numero de variables: ", sum(reg.summary$which[idx_menor,]), "\n"))
reg.summary$which[idx_menor,]
# Mejor subset segun adjr2
adjr2s = reg.summary$adjr2
idx_menor = which.min(adjr2s)
reg.summary$which[idx_menor,]
model_bic = lm(Y ~ X1 + X2 + X3 + X9 + X10 , data=data)
model_adjr2 = lm(Y ~ X10 , data=data)
ggplot() +
geom_point(mapping=aes(x=X,y=Y)) +
geom_line(mapping=aes(x=X,y=predicciones_bic, color="BIC")) +
geom_line(mapping=aes(x=X,y=predicciones_adjr2, color="AdjR2")) +
theme_bw() +
theme(legend.position.inside=c(0.4,0.8))
model_bic = lm(Y ~ X1 + X2 + X3 + X9 + X10 , data=data)
model_adjr2 = lm(Y ~ X10 , data=data)
model_bic = lm(Y ~ X1 + X2 + X3 + X9 + X10 , data=data)
model_adjr2 = lm(Y ~ X10 , data=data)
```{r}
predicciones_bic = predict(model_bic, newdata=data)
predicciones_adjr2 = predict(model_adjr2, newdata=data)
ggplot() +
geom_point(mapping=aes(x=X,y=Y)) +
geom_line(mapping=aes(x=X,y=predicciones_bic, color="BIC")) +
geom_line(mapping=aes(x=X,y=predicciones_adjr2, color="AdjR2")) +
theme_bw() +
theme(legend.position.inside=c(0.4,0.8))
ggplot() +
geom_point(mapping=aes(x=X,y=Y)) +
geom_line(mapping=aes(x=X,y=predicciones_bic, color="BIC")) +
geom_line(mapping=aes(x=X,y=predicciones_adjr2, color="AdjR2")) +
theme_bw() +
theme(legend.position.inside=c(0.4,0.8))
ggplot() +
geom_point(mapping=aes(x=X,y=Y)) +
geom_line(mapping=aes(x=X,y=predicciones_bic, color="BIC")) +
geom_line(mapping=aes(x=X,y=predicciones_adjr2, color="AdjR2")) +
theme_bw() +
theme(legend.position=c(0.4,0.8))
ggsave("./documento/figure/p1_forward_compare.pdf", width=6, height=4)
ggplot() +
geom_point(mapping=aes(x=X,y=Y)) +
geom_line(mapping=aes(x=X,y=predicciones_bic, color="BIC")) +
geom_line(mapping=aes(x=X,y=predicciones_adjr2, color="AdjR2")) +
theme_bw() +
theme(legend.position=c(0.4,0.8)) +
labs(color="Modelos")
ggsave("./documento/figure/p1_forward_compare.pdf", width=6, height=4)
regfit.backward <- regsubsets(Y ~ ., data = data, method="backward")
reg.summary <- summary(regfit.backward)
print(reg.summary)
regfit.backward <- regsubsets(Y ~ ., data = data, method="backward")
reg.summary <- summary(regfit.backward)
print(reg.summary)
# Mejor subset segun bic
bics = reg.summary$bic
idx_menor = which.min(bics)
cat(paste("Numero de variables: ", sum(reg.summary$which[idx_menor,]), "\n"))
reg.summary$which[idx_menor,]
# Mejor subset segun adjr2
adjr2s = reg.summary$adjr2
idx_menor = which.min(adjr2s)
reg.summary$which[idx_menor,]
# Mejor subset segun bic
bics = reg.summary$bic
idx_menor = which.min(bics)
cat(paste("Numero de variables: ", sum(reg.summary$which[idx_menor,]), "\n"))
reg.summary$which[idx_menor,]
# Mejor subset segun adjr2
adjr2s = reg.summary$adjr2
idx_menor = which.min(adjr2s)
reg.summary$which[idx_menor,]
model_bic = lm(Y ~ X4 + X5 + X6 + X7 + X8 , data=data)
model_adjr2 = lm(Y ~ X5 , data=data)
predicciones_bic = predict(model_bic, newdata=data)
predicciones_adjr2 = predict(model_adjr2, newdata=data)
save("./documento/figure/p1_backward_compare.pdf", width=6, height=4)
ggplot() +
geom_point(mapping=aes(x=X,y=Y)) +
geom_line(mapping=aes(x=X,y=predicciones_bic, color="BIC")) +
geom_line(mapping=aes(x=X,y=predicciones_adjr2, color="AdjR2")) +
theme_bw() +
theme(legend.position=c(0.4,0.8)) +
labs(color="Modelos")
gg
ggplot() +
geom_point(mapping=aes(x=X,y=Y)) +
geom_line(mapping=aes(x=X,y=predicciones_bic, color="BIC")) +
geom_line(mapping=aes(x=X,y=predicciones_adjr2, color="AdjR2")) +
theme_bw() +
theme(legend.position=c(0.4,0.8)) +
labs(color="Modelos")
ggsave("./documento/figure/p1_backward_compare.pdf", width=6, height=4)
set.seed(123)
n <- 1000
p <- 20
X <- matrix(rnorm(n * p), n, p)
beta <- c(rnorm(10), rep(0, 10))
epsilon <- rnorm(n)
Y <- X %*% beta + epsilon
train_indices <- sample(1:n, 100)
X_train <- X[train_indices, ]
Y_train <- Y[train_indices]
X_test <- X[-train_indices, ]
Y_test <- Y[-train_indices]
set.seed(2) # Semilla para reproducir la división
n_train <- 100
n_test <- n - n_train # 900
# Muestreamos 100 índices para el conjunto de entrenamiento
train_indices <- sample(1:n, n_train)
# Creamos los conjuntos
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
# 1. Función auxiliar para predecir con 'regsubsets'
# (Esta función es necesaria para obtener el MSE de prueba )
predict.regsubsets <- function(object, newdata, id, ...) {
# Obtener la fórmula original
form <- as.formula(object$call[[2]])
# Crear la matriz de diseño (model.matrix) con los datos nuevos
mat <- model.matrix(form, newdata)
# Obtener los coeficientes del modelo 'id'
coef_k <- coef(object, id = id)
# Obtener los nombres de las variables en ese modelo
xvars <- names(coef_k)
# Multiplicar las columnas de la matriz de diseño
# por los coeficientes seleccionados
mat[, xvars] %*% coef_k
}
# 2. Realizar la selección de mejores subconjuntos en los datos de entrenamiento
best_model_train <- regsubsets(Y ~ ., data = train_data, nvmax = p)
# 3. Preparar vectores para guardar los MSE
train_mse <- rep(NA, p)
# 1. Función auxiliar para predecir con 'regsubsets'
# (Esta función es necesaria para obtener el MSE de prueba )
predict.regsubsets <- function(object, newdata, id, ...) {
# Obtener la fórmula original
form <- as.formula(object$call[[2]])
# Crear la matriz de diseño (model.matrix) con los datos nuevos
mat <- model.matrix(form, newdata)
# Obtener los coeficientes del modelo 'id'
coef_k <- coef(object, id = id)
# Obtener los nombres de las variables en ese modelo
xvars <- names(coef_k)
# Multiplicar las columnas de la matriz de diseño
# por los coeficientes seleccionados
mat[, xvars] %*% coef_k
}
# 2. Realizar la selección de mejores subconjuntos en los datos de entrenamiento
best_model_train <- regsubsets(Y ~ ., data = train_data, nvmax = p)
set.seed(123)
n <- 1000
p <- 20
X <- matrix(rnorm(n * p), n, p)
beta <- c(rnorm(10), rep(0, 10))
epsilon <- rnorm(n)
Y <- X %*% beta + epsilon
set.seed(2) # Semilla para reproducir la división
n_train <- 100
n_test <- n - n_train # 900
# Muestreamos 100 índices para el conjunto de entrenamiento
train_indices <- sample(1:n, n_train)
# Creamos los conjuntos
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
# 1. Función auxiliar para predecir con 'regsubsets'
# (Esta función es necesaria para obtener el MSE de prueba )
predict.regsubsets <- function(object, newdata, id, ...) {
# Obtener la fórmula original
form <- as.formula(object$call[[2]])
# Crear la matriz de diseño (model.matrix) con los datos nuevos
mat <- model.matrix(form, newdata)
# Obtener los coeficientes del modelo 'id'
coef_k <- coef(object, id = id)
# Obtener los nombres de las variables en ese modelo
xvars <- names(coef_k)
# Multiplicar las columnas de la matriz de diseño
# por los coeficientes seleccionados
mat[, xvars] %*% coef_k
}
# 2. Realizar la selección de mejores subconjuntos en los datos de entrenamiento
best_model_train <- regsubsets(Y ~ ., data = train_data, nvmax = p)
# Instalar y cargar la biblioteca 'leaps'
# install.packages("leaps")
library(leaps)
set.seed(1) # Semilla para reproducir la simulación
n <- 1000
p <- 20
# 1. Crear la matriz de predictores X
X <- matrix(rnorm(n * p), n, p)
# 2. Crear el vector de coeficientes beta
# La mayoría de los coeficientes serán 0
beta <- rep(0, p)
# Damos valor solo a 5 de ellos (el modelo verdadero)
beta[c(2, 5, 8, 13, 19)] <- c(2.5, -1.5, 1, 0.8, -2)
# 3. Crear el ruido épsilon
eps <- rnorm(n)
# 4. Generar la respuesta Y (Y = X*beta + eps)
Y <- X %*% beta + eps
# 5. Crear el data frame
data <- data.frame(Y = Y, X = X)
names(data) <- c("Y", paste0("X", 1:p))
set.seed(2) # Semilla para reproducir la división
n_train <- 100
n_test <- n - n_train # 900
# Muestreamos 100 índices para el conjunto de entrenamiento
train_indices <- sample(1:n, n_train)
# Creamos los conjuntos
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
# 1. Función auxiliar para predecir con 'regsubsets'
# (Esta función es necesaria para obtener el MSE de prueba )
predict.regsubsets <- function(object, newdata, id, ...) {
# Obtener la fórmula original
form <- as.formula(object$call[[2]])
# Crear la matriz de diseño (model.matrix) con los datos nuevos
mat <- model.matrix(form, newdata)
# Obtener los coeficientes del modelo 'id'
coef_k <- coef(object, id = id)
# Obtener los nombres de las variables en ese modelo
xvars <- names(coef_k)
# Multiplicar las columnas de la matriz de diseño
# por los coeficientes seleccionados
mat[, xvars] %*% coef_k
}
# 2. Realizar la selección de mejores subconjuntos en los datos de entrenamiento
best_model_train <- regsubsets(Y ~ ., data = train_data, nvmax = p)
# 3. Preparar vectores para guardar los MSE
train_mse <- rep(NA, p)
test_mse <- rep(NA, p)
# 4. Calcular MSE para cada tamaño de modelo (k=1 hasta k=20)
for (k in 1:p) {
# (c) Calcular el MSE de ENTRENAMIENTO
pred_train <- predict.regsubsets(best_model_train, train_data, id = k)
train_mse[k] <- mean((train_data$Y - pred_train)^2)
# (d) Calcular el MSE de PRUEBA
pred_test <- predict.regsubsets(best_model_train, test_data, id = k)
test_mse[k] <- mean((test_data$Y - pred_test)^2)
}
# 5. Graficar (c) y (d) juntos para comparación
# Guardar la gráfica en un archivo PNG
png("problema2_mse_comparacion.png", width = 8, height = 6, units = "in", res = 300)
y_range <- range(c(train_mse, test_mse)) # Para que ambas curvas quepan
plot(1:p, train_mse, type = "o", col = "blue", pch = 19,
ylim = y_range,
xlab = "Número de Predictores (k)",
ylab = "Mean Squared Error (MSE)",
main = "Comparación de MSE de Entrenamiento vs. Prueba")
lines(1:p, test_mse, type = "o", col = "red", pch = 19)
legend("topright",
legend = c("MSE de Entrenamiento", "MSE de Prueba"),
col = c("blue", "red"),
pch = 19, lty = 1)
# (e) Encontrar el mínimo MSE de prueba y marcarlo
best_k_test <- which.min(test_mse)
abline(v = best_k_test, col = "red", lty = 2, lwd = 2) # Línea vertical punteada
text(best_k_test + 2, y_range[1] + diff(y_range)*0.1,
paste("Mínimo en k =", best_k_test), col = "red")
dev.off() # Cerrar el archivo PNG
cat("--- (e) Mejor modelo según MSE de Prueba ---\n")
cat("El MSE de prueba se minimiza en k =", best_k_test, "\n")
cat("MSE de prueba mínimo:", test_mse[best_k_test], "\n\n")
# 1. Coeficientes del modelo verdadero (los que definimos en 'beta')
cat("--- (f) Comparación de Coeficientes ---\n")
cat("Modelo Verdadero (k = 5 predictores):\n")
true_coefs <- data.frame(
Predictor = paste0("X", c(2, 5, 8, 13, 19)),
Coeficiente = c(2.5, -1.5, 1, 0.8, -2)
)
print(true_coefs)
cat("\n")
# 2. Coeficientes del modelo óptimo (k = best_k_test)
cat("Coeficientes del Mejor Modelo (k =", best_k_test, ") según MSE de prueba:\n")
best_model_coefs <- coef(best_model_train, id = best_k_test)
print(best_model_coefs)
