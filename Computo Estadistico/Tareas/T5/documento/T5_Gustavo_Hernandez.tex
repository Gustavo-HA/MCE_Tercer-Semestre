% Optimizado para compilación rápida
\documentclass[paper=letter, fontsize=11pt, draft=false]{scrartcl}

% Modifications to layout
\usepackage[shortlabels]{enumitem} % Incisos
\def\code#1{\texttt{#1}} % \code{} for monospaced text
\newcommand{\RNum}[1]{\footnotesize\uppercase\expandafter{\romannumeral #1\relax\normalsize}} % Roman numbers

\usepackage{subcaption} % 2x2 graphs
\usepackage{mwe}
\usepackage{float} % [H] in graphics
\usepackage[hidelinks]{hyperref}  % Hipervínculos en la TOC

\usepackage{booktabs,siunitx,listings}
\usepackage[most]{tcolorbox}
\tcbuselibrary{theorems}
\usepackage{cleveref}

% Typography and layout packages
\usepackage{graphicx}
\usepackage{verbatim}
% \usepackage{xcolor}
\usepackage[spanish,es-nodecimaldot]{babel} % Language and hyphenation
\usepackage{amsmath, amsfonts, amsthm, amssymb} % Math packages
\newtheorem{definition}{Definición} % definition
\usepackage{fancyvrb}
\usepackage{sectsty} % Customize section commands
\usepackage{geometry} % Modify margins
\usepackage{titlesec} % Customize section titles
\geometry{margin=3cm,top=2.5cm,bottom=2.5cm} % Simplified geometry
\allsectionsfont{\centering \normalfont\scshape} % Center and style section titles

% Header and footer customization
\usepackage{fancyhdr}
\pagestyle{fancyplain}
\fancyhead[L]{\slshape} % Remove section title from header
\fancyhead[C]{} % Header center
\fancyhead[R]{\thepage} % Header right with page number
\fancyfoot[L]{} % Footer left
\fancyfoot[C]{} % Footer center
\fancyfoot[R]{\small \slshape Gustavo Hernández Angeles} % Footer right
\renewcommand{\headrulewidth}{0.4pt} % Header rule
\renewcommand{\footrulewidth}{0.4pt} % Footer rule
\setlength{\headheight}{14.5pt} % Header height

% Paragraph settings
\setlength\parindent{0pt}
\setlength{\parskip}{1ex}

% Section spacing
\titlespacing*{\section}{0cm}{0.50cm}{0.25cm}

% --- Theorems, lemma, corollary, postulate, definition ---
\definecolor{Pantone209C}{HTML}{64293e}

\newcounter{problemcounter}

\numberwithin{equation}{problemcounter} % Number equations within problems
\numberwithin{figure}{problemcounter} % Number figures within problems
\numberwithin{table}{problemcounter} % Number tables within problems
\numberwithin{subsection}{problemcounter} 

\newtcbtheorem[auto counter]{problem}{Ejercicio}{
    enhanced,
    breakable,
    colback = gray!5,
    colframe = gray!5,
    boxrule = 0.5pt,
    sharp corners,
    borderline west = {2mm}{0mm}{Pantone209C},
    fonttitle = \bfseries\sffamily,
    coltitle = Pantone209C,
    drop fuzzy shadow,
    parbox = false,
    before skip = 3ex,
    after skip = 3ex
}{problem}
\makeatletter
\renewenvironment{problem}[2][]{%
    \refstepcounter{problemcounter}%
    \addcontentsline{toc}{section}{\protect\numberline{\theproblemcounter}Ejercicio \theproblemcounter: #2}%
    \begin{tcolorbox}[
        enhanced,
        breakable,
        colback = gray!5,
        colframe = gray!5,
        boxrule = 0.5pt,
        sharp corners,
        borderline west = {2mm}{0mm}{Pantone209C},
        fonttitle = \bfseries\sffamily,
        coltitle = Pantone209C,
        drop fuzzy shadow,
        parbox = false,
        before skip = 3ex,
        after skip = 3ex,
        title={Ejercicio \theproblemcounter: #2}
    ]
}{%
    \end{tcolorbox}
}
\makeatother

\tcbuselibrary{skins, breakable}
% Custom command for a horizontal rule
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} 

% Custom section titles with numbering
\titleformat{\section}
{\normalfont\Large\bfseries}{\thesection}{1em}{}

\titleformat{\subsection}
{\normalfont\large\bfseries}{\thesubsection}{1em}{}

\titleformat{\subsubsection}
{\normalfont\normalsize\bfseries}{\thesubsubsection}{1em}{}

% Title and author
\title{	
    \begin{center}
        \includegraphics[width=3cm]{figure/template/cimat-logo.png} % Adjust size as needed
    \end{center}
    \vspace{0.5cm}
    \normalfont \normalsize 
    \textbf{\Large   Centro de Investigación en Matemáticas} \\
    \Large Unidad Monterrey \\ [25pt] 
    \horrule{1pt} \\[0.4cm] % Thin top horizontal rule
    \huge Análisis Multimodal\\
    \Large Tarea 2\\ 
    \horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{\large Gustavo Hernández Angeles}    

\date{\normalsize\today} % Today's date

\begin{document}
\maketitle % Print the title
\thispagestyle{empty}
\newpage

\tableofcontents
























































%%%%%%%%%%% PROBLEMA 1 %%%%%%%%%%%
\newpage
\begin{problem}{}
Utilizando el conjunto de datos \texttt{College} disponible en la libreria \texttt{ISLR}, predice el número de solicitudes recibidas (\texttt{Apps}) utilizando las otras variables del conjunto de datos.

\begin{enumerate}[a)]
  \item Divide el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba.
  \item Ajusta un modelo lineal utilizando mínimos cuadrados en el conjunto de entrenamiento y reporta el error de prueba obtenido.
  \item Ajusta un modelo de regresión ridge en el conjunto de entrenamiento, con \(\lambda\) elegido por validación cruzada. Reporta el error de prueba obtenido.
  \item Ajusta un modelo Lasso en el conjunto de entrenamiento, con \(\lambda\) elegido por validación cruzada. Reporta el error de prueba obtenido, junto con el número de estimaciones de coeficientes distintos de cero.
  \item Ajusta un modelo PCR en el conjunto de entrenamiento, con M elegido por validación cruzada. Reporta el error de prueba obtenido, junto con el valor de M seleccionado por validación cruzada.
  \item Ajusta un modelo PLS en el conjunto de entrenamiento, con M elegido por validación cruzada. Reporta el error de prueba obtenido, junto con el valor de M seleccionado por validación cruzada.
  \item Comenta los resultados obtenidos. ¿Con qué precisión podemos predecir la cantidad de solicitudes universitarias recibidas?  ¿Hay mucha diferencia entre los errores de prueba resultantes de estos cinco enfoques? 
  \item Propón un modelo (o un conjunto de modelos) que parezca funcionar bien en este conjunto de datos y justifica tu respuesta. Asegúrate de evaluar el rendimiento del modelo utilizando el error del conjunto de validación, la validación cruzada o alguna otra alternativa razonable, en lugar de utilizar el error de entrenamiento. ¿El modelo que elegiste incluye todas las características del conjunto de datos? ¿Por qué o por qué no? 
\end{enumerate}

\end{problem}

\subsection{Inciso a)}

Se utilizó el conjunto de datos \texttt{College} y, para evitar data leakage, se eliminaron las variables \texttt{Accept} y \texttt{Enroll} del análisis, ya que están determinadas después de \texttt{Apps} o están fuertemente condicionadas por ella; incluirlas inflaría artificialmente el desempeño en prueba. Posteriormente, se dividió el conjunto en entrenamiento y prueba usando un \(50\%\) para cada uno (muestra aleatoria con semilla fija).

\subsection{Inciso b)}

Se ajustó un modelo lineal utilizando Minimos Cuadrados Ordinarios (OLS) en el conjunto de entrenamiento, empleando todos los predictores. Las variables que resultaron ser estadísticamente significativas (con $p < 0.1$) en dicho modelo fueron:
\begin{itemize}
    \item \texttt{F.Undergrad} ($***$)
    \item \texttt{Room.Board} ($***$)
    \item \texttt{Expend} ($**$)
    \item \texttt{Grad.Rate} ($*$)
    \item \texttt{perc.alumni} ($.$)
\end{itemize}

mientras que las demás variables no mostraron significancia estadística en el modelo ajustado. Al evaluar el rendimiento de este modelo en el conjunto de prueba, se obtuvo un Error Cuadrático Medio (MSE) de \textbf{2,551,734}. Esto corresponde a un Error Cuadrático Medio Raíz (RMSE) de \textbf{1,597.4}.

\subsection{Inciso c)}

Se ajustó una regresión \textit{Ridge} con validación cruzada de 5 pliegues para seleccionar el parámetro de regularización \(\lambda\). El valor de $\lambda$ que minimiza el error \(\lambda_{\min}\) elegido por CV fue \textbf{12.07}, y \(\lambda_{1se}=\) \textbf{4498.43} como alternativa más parsimoniosa (ver Figura \ref{fig:lambda_selection}). Con \(\lambda_{\min}\), el desempeño en prueba fue: MSE \textbf{2,530,947} (RMSE \textbf{1,590.9}). Con \(\lambda_{1se}\) el error aumentó a MSE \textbf{3,552,978} (RMSE \textbf{1,884.9}).

\subsection{Inciso d)}

Se ajustó un modelo \textit{LASSO} también con validación cruzada de 5 pliegues. Se obtuvo \(\lambda_{\min}=\) \textbf{86.85} y \(\lambda_{1se}=\) \textbf{1098.54}. Con \(\lambda_{\min}\), el error de prueba fue MSE \textbf{2,395,665} (RMSE \textbf{1,547.8}), y con \(\lambda_{1se}\) el MSE fue \textbf{3,438,634}. El modelo con \(\lambda_{\min}\) seleccionó 9 coeficientes distintos de cero, correspondientes a las variables: \texttt{Top10perc}, \texttt{Top25perc}, \texttt{F.Undergrad}, \texttt{Room.Board}, \texttt{Personal}, \texttt{S.F.Ratio}, \texttt{perc.alumni}, \texttt{Expend} y \texttt{Grad.Rate}.

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figure/lambda_ridge.png}
        \caption{Selección de $\lambda$ por validación cruzada – Ridge.}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figure/lambda_lasso.png}
        \caption{Selección de $\lambda$ por validación cruzada – Lasso.}
    \end{subfigure}
    \caption{Comparación de curvas de validación cruzada para la selección de $\lambda$. Las líneas verticales indican $\lambda_{\min}$ y $\lambda_{1se}$.}
    \label{fig:lambda_selection}
\end{figure}

\subsection{Inciso e)}

Para PCR (componentes principales como regresores), con escalamiento y validación cruzada, el menor MSEP se obtuvo con \(M=\) 12 componentes. En prueba, el desempeño fue MSE \textbf{2,389,249} (RMSE \textbf{1,545.7}). Nótese que con 6 componentes se explica aproximadamente el 80.8\% de la varianza en $\mathbf{X}$ y 61.7\% de \texttt{Apps}; con 9 componentes, 91.1\% en $\mathbf{X}$ y 62.7\% en \texttt{Apps}. Como se espera, aumentar el número de componentes no mejora la explicación de \texttt{Apps} significativamente.

\subsection{Inciso f)}

Para PLSR (componentes latentes que maximizan covarianza), la validación cruzada sugirió \(M=\) \textbf{4} componentes. En el conjunto de prueba se obtuvo MSE \textbf{2,457,676} (RMSE \textbf{1,567.7}).

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figure/m_pcr.png}
        \caption{Curva de MSEP para PCR.}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figure/m_pls.png}
        \caption{Curva de MSEP para PLSR.}
    \end{subfigure}
    \caption{Selección del número de componentes $M$ mediante validación cruzada.}
\end{figure}

En esta ocasión, el modelo con 4 componentes explica el 72.01\% de la varianza en \texttt{Apps}, lo que indica que PLSR logra una mejor explicación de la variable respuesta con menos componentes en comparación con PCR.



\subsection{Inciso g)}

Para entender el desempeño de los modelos, debemos entender la variable de respuesta \texttt{Apps}. Esta variable tiene un rango amplio, desde un mínimo de 81 hasta un máximo de 48,094 solicitudes, con un promedio de aproximadamente 3,002 y una mediana de 1,558. La distribución es altamente sesgada a la derecha, con algunas universidades recibiendo un número excepcionalmente alto de solicitudes.

% Resumen de errores de prueba
\begin{table}[H]
    \centering
    \caption{Errores de prueba por modelo}
    \label{tab:errores-modelos}
    \begin{tabular}{lrr}
        \toprule
        \textbf{Modelo} & \textbf{MSE} & \textbf{RMSE} \\
        \midrule
        OLS & 2,551,734 & 1,597.4 \\
        Ridge ($\lambda_{\min}=12.07$) & 2,530,947 & 1,590.9 \\
        Lasso ($\lambda_{\min}=86.85$) & 2,395,665 & 1,547.8 \\
        PCR ($M=12$) & \textbf{2,389,249} & \textbf{1,545.7} \\
        PLSR ($M=4$) & 2,457,676 & 1,567.7 \\
        \bottomrule
    \end{tabular}
\end{table}

En términos de precisión, todos los métodos logran errores de prueba de magnitud similar: RMSE entre \(\approx\) 1545 y 1600 solicitudes. Dado que el promedio de \texttt{Apps} ronda \(\sim\) $3000$, el error típico es del orden de la mitad del promedio, lo que indica capacidad predictiva moderada pero con variabilidad sustancial no explicada. Entre los enfoques (Cuadro \ref{tab:errores-modelos}), \textbf{PCR (M=12)} y \textbf{Lasso} con \(\lambda_{\min}\) fueron los mejores (MSE \(\approx 2.39\times10^6\)), seguidos de \textbf{Ridge} (ligeramente peor) y \textbf{PLSR}. El modelo lineal MCO quedó rezagado respecto a PCR/Lasso, aunque no por un margen muy grande.

\subsection{Inciso h)}

Una propuesta razonable es utilizar \textbf{Lasso con \(\lambda_{\min}\)}: ofrece un desempeño competitivo (prácticamente el mejor MSE) y además un modelo \textit{parco} con solo 9 predictores, lo que facilita interpretación y despliegue. Usar \(\lambda_{1se}\) reduciría aún más la complejidad, pero en este caso incurre en una pérdida de precisión considerable. Como alternativa si la interpretabilidad de coeficientes es secundaria, \textbf{PCR con \(M=12\)} proporciona un error prácticamente indistinguible del de Lasso.

El conjunto de covariables retenido por Lasso incluye factores plausibles desde el punto de vista sustantivo (tamaño de matrícula, cuotas, gasto institucional y tasa de graduación), lo que respalda su uso en la práctica.


























































































%%%%%%%%%%% PROBLEMA 2 %%%%%%%%%%%
\newpage
\begin{problem}{}
Es bien sabido que la regresión ridge tiende a dar valores de coeficientes similares a las variables correlacionadas, mientras que lasso puede dar valores de coeficientes totalmente diferentes a las variables correlacionadas. Se explorará esta propiedad en un entorno sencillo.

Supongamos que \(n=2\), \(p=2\), \(x_{11}=x_{12}\), \(x_{21}=x_{22}\). Además, supongamos que \(y_{1}+y_{2}=0\) y \(x_{12}+x_{22}=0\), de modo que la estimación del intercepto en mínimos cuadrados, regresión de Ridge o en el modelo de lasso es cero: \(\hat{\gamma}_{0}=0\).

\begin{enumerate}[a)]
  \item Plantea el problema de la optimización con la regresión ridge bajo estas suposiciones.
  \item Argumenta que bajo estas suposiciones, las estimaciones de los coeficientes de ridge satisfacen \(\hat{\beta}_{1}=\hat{\beta}_{2}\).
  \item Plantea el problema de la optimización con la regresión lasso bajo estas suposiciones.
  \item Argumenta que en este contexto, los coeficientes de lasso \(\hat{\beta}_{1}\) y \(\hat{\beta}_{2}\) no son únicos; es decir, hay muchas soluciones posibles al problema de optimización en (c). Describe estas soluciones.
\end{enumerate}

\end{problem}


\subsection{Inciso a)}

Bajo las suposiciones $n=2$, $p=2$, $x_{11}=x_{12}$ y $x_{21}=x_{22}$, y además $y_1+y_2=0$ y $x_{12}+x_{22}=0$, el intercepto óptimo es cero. Denotando $s_i=x_{i1}=x_{i2}$, la regresión ridge busca
\[
\min_{\beta_1,\beta_2} \sum_{i=1}^2 \big(y_i - \beta_1 x_{i1} - \beta_2 x_{i2}\big)^2 
\; +\; \lambda\,(\beta_1^2+\beta_2^2)
\;=\; \min_{\beta_1,\beta_2} \sum_{i=1}^2 \big(y_i - (\beta_1+\beta_2) s_i\big)^2 + \lambda\,(\beta_1^2+\beta_2^2).
\]

\subsection{Inciso b)}

Sea $\theta = \beta_1+\beta_2$ y $\delta = \beta_1-\beta_2$. Con esta reparametrización,
\[
\sum_{i=1}^2 \big(y_i - (\beta_1+\beta_2) s_i\big)^2 = \sum_{i=1}^2 (y_i - \theta s_i)^2,
\quad \text{y} \quad \beta_1^2+\beta_2^2 = \tfrac{1}{2}(\theta^2+\delta^2).
\]
Así, el funcional de ridge queda
\[ 
L(\theta,\delta) = \sum_{i=1}^2 (y_i - \theta s_i)^2 + (\lambda/2)(\theta^2+\delta^2),
\]
que para $\theta$ fijo es estrictamente creciente en $\delta^2$. Por lo tanto, el mínimo ocurre en $\delta^{\ast}=0$, es decir, $\hat{\beta}_1=\hat{\beta}_2$.

\subsection{Inciso c)}

El problema de optimización para \textit{lasso} bajo las mismas suposiciones es
\[
\min_{\beta_1,\beta_2} \sum_{i=1}^2 \big(y_i - (\beta_1+\beta_2) s_i\big)^2 + \lambda\,(|\beta_1|+|\beta_2|).
\]

\subsection{Inciso d)}

Con $\theta=\beta_1+\beta_2$, la parte de ajuste depende solo de $\theta$, mientras que la penalización \(|\beta_1|+|\beta_2|\) satisface \(|\beta_1|+|\beta_2|\ge |\theta|\) con igualdad cuando $\beta_1$ y $\beta_2$ comparten el signo de $\theta$ (o alguno es cero). Sea $\theta^{\ast}$ el minimizador del problema unidimensional
\[ \min_{\theta} \sum_{i=1}^2 (y_i - \theta s_i)^2 + \lambda\,|\theta|. \]
Entonces, todo par $(\hat{\beta}_1,\hat{\beta}_2)$ que cumpla
\[
\hat{\beta}_1+\hat{\beta}_2=\theta^{\ast} \quad \text{y} \quad \hat{\beta}_1\,\hat{\beta}_2\ge 0
\]
alcanza el mismo valor óptimo: la pérdida de ajuste es idéntica (depende solo de $\theta^{\ast}$) y la penalización vale $|\theta^{\ast}|$. Por tanto, los coeficientes de lasso no son únicos: el conjunto solución es el segmento de recta
\[
\big\{(t,\,\theta^{\ast}-t):\; t\in[0,\theta^{\ast}]\big\} \quad \text{si } \theta^{\ast}>0,
\]
\[
\big\{(t,\,\theta^{\ast}-t):\; t\in[\theta^{\ast},0]\big\} \quad \text{si } \theta^{\ast}<0,
\]
incluyendo como extremos las soluciones $(\theta^{\ast},0)$ y $(0,\theta^{\ast})$. En el caso límite $\theta^{\ast}=0$, la solución única es $(0,0)$.



\end{document}
